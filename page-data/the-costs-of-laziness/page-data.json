{"componentChunkName":"component---node-modules-lekoarts-gatsby-theme-minimal-blog-core-src-templates-post-query-tsx","path":"/the-costs-of-laziness","result":{"data":{"post":{"slug":"/the-costs-of-laziness","title":"The costs of laziness","date":"16.03.2023","tags":[{"name":"Rust","slug":"rust"},{"name":"Performance","slug":"performance"},{"name":"Async","slug":"async"},{"name":"Distibuted Systems","slug":"distibuted-systems"}],"description":"The costs of laziness","canonicalUrl":null,"body":"var _excluded = [\"components\"];\nfunction _extends() { _extends = Object.assign ? Object.assign.bind() : function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n/* @jsxRuntime classic */\n/* @jsx mdx */\n\nvar _frontmatter = {\n  \"title\": \"The costs of laziness\",\n  \"date\": \"2023-03-16T00:00:00.000Z\",\n  \"description\": \"The costs of laziness\",\n  \"tags\": [\"Rust\", \"Performance\", \"Async\", \"Distibuted Systems\"]\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n    props = _objectWithoutProperties(_ref, _excluded);\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h1\", null), mdx(\"p\", null, \"Lazy evaluation is a concept that appears in multiple branches of computer science.\\nIt is the idea to pre-emptively do less work and defer the computation until it is needed, as opposed to eager evaluation.\\nThe problem with such technique is that it can have noticeable overheads such as bookkeeping.\\nI won't talk about laziness in the context of Haskell as I'm not qualified and the internet is already filled with that.\"), mdx(\"p\", null, \"It is often introduced as a functional programming concept but it also exists in the C-family programming languages.\\nFunctions are lazy by nature, function pointers (and lambdas or closures) by themselves do nothing -- until called.\"), mdx(\"p\", null, \"Let's set the stage with an example, suppose we need to add tracing to some application that processes a list of objects.\\nOne way of implementing this is the following:\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-rust\"\n  }, \"fn trace(condition: bool, message: String) {\\n    if condition {\\n        println!(\\\"{}\\\", message);\\n    }\\n}\\n\\nfn consume(objects: Vec<Object>) {\\n    for obj in objects {\\n        trace(obj.id % N == 0, format!(\\\"consumed {} objects\\\", obj.id));\\n        trace(obj.is_defective(), format!(\\\"{} is defective\\\", obj));\\n    }\\n}\\n\")), mdx(\"p\", null, \"The above code may appear sensible as it is DRY and encapsulates the tracing logic inside a function, but it has a major flaw that won't be catched by the compiler.\"), mdx(\"p\", null, \"-- \"), mdx(\"p\", null, \"For each iteration of the loop, the program will construct the message as if the condition happened.\", mdx(\"br\", {\n    parentName: \"p\"\n  }), \"\\n\", \"The message has to materialize before being passed as an argument.\", mdx(\"br\", {\n    parentName: \"p\"\n  }), \"\\n\", \"This has dramatic performance consequences.  \"), mdx(\"p\", null, \"One way of fixing this is to use higher order functions, by wrapping the message in a closure, the message won't be eagerly executed at the call site but only when required.\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-rust\"\n  }, \"fn trace(condition: bool, message: impl FnOnce() -> String) {\\n    if condition {\\n        println!(\\\"{}\\\", message());\\n    }\\n}\\n\\nfn consume(objects: Vec<Object>) {\\n    for obj in objects {\\n        trace(obj.id % N == 0, || format!(\\\"consumed {} objects\\\", obj.id));\\n        trace(obj.is_defective(), || format!(\\\"{} is defective\\\", obj));\\n    }\\n}\\n\")), mdx(\"p\", null, \"This works, but it would be preferable to have a type that encapsulates the formatting logic and only materializes the message when needed, and that is exactly what \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"Arguments\"), \" is.  \"), mdx(\"p\", null, \"It is a lazy structure that represents the formatted message, it is also faster than our string producing closure since, by virtue of laziness, prevents intermediate string allocation and writes directly to the writer.  \"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-rust\"\n  }, \"fn trace(condition: bool, message: std::fmt::Arguments) {\\n    if condition {\\n        println!(\\\"{}\\\", message);\\n    }\\n}\\n\\nfn consume(objects: Vec<Object>) {\\n    for obj in objects {\\n        trace(obj.id % N == 0, { format_args!(\\\"consumed {} objects\\\", obj.id) });\\n        trace(obj.is_defective(), format_args!(\\\"{} is defective\\\", obj));\\n    }\\n}\\n\")), mdx(\"p\", null, \"Actually this is not the only lazy construct used in the code above, let's desugar the for loop.\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-rust\"\n  }, \"fn consume(objects: Vec<Object>) {\\n    match IntoIterator::into_iter(objects) {\\n        mut iterator => loop {\\n            match iterator.next() {\\n                None => break,\\n                Some(obj) => {\\n                    trace(obj.id % N == 0, { format_args!(\\\"consumed {} objects\\\", obj.id) });\\n                    trace(obj.is_defective(), format_args!(\\\"{} is defective\\\", obj));\\n                }\\n            }\\n        }\\n    }\\n}\\n\")), mdx(\"p\", null, \"The code might seem cryptic but you could notice that each iteration of the loop requires a function call: \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"next()\"), \"; iteration is also lazy!\\nThe advantage of using lazy iteration is that it allows partial consumption (e.g. break), this could save unnecessary work and allow the usage of infinite data structures like \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"Range\"), \".\", mdx(\"br\", {\n    parentName: \"p\"\n  }), \"\\n\", \"It relates to the iterator design pattern which is an increasingly popular feature in programming languages.\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-rust\"\n  }, \"pub trait Iterator {\\n    type Item;\\n\\n    fn next(&mut self) -> Option<Self::Item>;\\n}\\n\")), mdx(\"p\", null, \"This kind of abstraction seems to trade-off performance for readability but it is actually a zero runtime cost abstraction.\\nAs everything is statically dispatched, the compiler is allowed to aggressively inline and optimize the code.\\nThis is not guaranteed but it has rarely generated bad assembly in my experience.\", mdx(\"br\", {\n    parentName: \"p\"\n  }), \"\\n\", \"This abstraction enables the composition of simple transformations on iterators which would be clunkier in an imperative style, for example:\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-rust\"\n  }, \"/// finds the first element a + b = c + d\\n/// where a, b, c, d are cubes\\n/// in constant memory\\nfn taxicab_two() -> Option<usize> {\\n    let cube = |i: usize| i * i * i;\\n\\n    (0..)\\n        .map(|i| {\\n            (\\n                (cube(i), (0..i).map(cube)),\\n                (i + 1..).map(|j| (cube(j), (0..j).map(cube))),\\n            )\\n        })\\n        .find_map(|(targets, candidates)| {\\n            let (a, mut bs) = targets;\\n            bs.find_map(|b| {\\n                let target = a + b;\\n                candidates\\n                    .clone() // at worse a memcpy of a small structure\\n                    .take_while(|&(c, _)| c <= target)\\n                    .find_map(|(c, ds)| {\\n                        ds.map(|d| c + d)\\n                            .skip_while(|&candidate| candidate < target)\\n                            .next()\\n                            .filter(|&candidate| candidate == target)\\n                    })\\n            })\\n        })\\n}\\n\\n#[cfg(test)]\\nmod tests {\\n    use super::*;\\n\\n    #[test]\\n    fn it_works() {\\n        assert_eq!(taxicab_two(), Some(1729));\\n    }\\n}\\n\")), mdx(\"p\", null, \"It can get kind of messy with nested iterators but in the common case they're a pleasure to work with!\"), mdx(\"p\", null, \"Another benefit of this API is that it guarantees (in the common case of \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"slice::Iter\"), \") sequential access.\\nThis forces the user to write code that is friendlier to the hardware due to cache locality and memory prefetching, while also making it easier for the compiler to autovectorize and remove bound checks.\"), mdx(\"p\", null, \"-- \"), mdx(\"p\", null, \"One problem I haven't mentioned yet about lazy evaluation is debugging.\", mdx(\"br\", {\n    parentName: \"p\"\n  }), \"\\n\", \"As the computation starts only when required, it is possible to end up with a very deep computation DAG making it tough to debug errors and extremely hard to solve performance regressions.\", mdx(\"br\", {\n    parentName: \"p\"\n  }), \"\\n\", \"Nonetheless, laziness leads to better code generation as the compiler has complete information of the computation, this is very apparent for processing engines like Spark.    \"), mdx(\"p\", null, \"Laziness can also appear for data structures, a common implementation of priority queue is a binary heap.\", mdx(\"br\", {\n    parentName: \"p\"\n  }), \"\\n\", \"Let's look at the following code: \"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-rust\"\n  }, \"fn top_k<T: Ord>(seq: impl IntoIterator<Item = T>, k: usize) -> impl Iterator<Item = T> {\\n    seq.into_iter()\\n        .collect::<BinaryHeap<_>>()\\n        .into_iter_sorted()\\n        .take(k)\\n}\\n\\n#[cfg(test)]\\nmod tests {\\n    use super::*;\\n\\n    #[test]\\n    fn it_works() {\\n        let array = [7, 22, 11, 34, 17, 52, 26, 13, 40, 20, 10, 5, 16, 8, 4, 2, 1];\\n        assert!(top_k(array, 3).eq([52, 40, 34]));\\n    }\\n}\\n\")), mdx(\"p\", null, \"The \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"top_k\"), \" function builds a binary heap and yields an iterator that lazily pops the top element at most k times.\\nSo the function takes a linear amount of time if unused and costs an extra logarithm for each iteration (i.e. \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"next()\"), \") of the output iterator.\\nMost of that work is spent maintaining the heap invariant.\"), mdx(\"p\", null, \"When that biggest element is popped, the data structure has to move things around to keep the invariant valid, but if we know that the heap is popping an element for the last time, we're wasting time!  \"), mdx(\"p\", null, \"This could be solved by having a function on the binary heap that consumes (i.e. takes ownership) of the data structure and returns the top most element in constant time... but algorithms rarely know when that would happen.\"), mdx(\"p\", null, \"One solution is to use a lazy variant of binary heaps, lazy fibonacci heaps and the like!\", mdx(\"br\", {\n    parentName: \"p\"\n  }), \"\\n\", \"Instead of resolving the invariant immediately, it defers the work until necessary.\", mdx(\"br\", {\n    parentName: \"p\"\n  }), \"\\n\", \"This allows for a better amortized time complexity for common operations.  \"), mdx(\"p\", null, \"In practice, it is very hard to beat the vector backed binary heap due the low amount of overhead; nevertheless, it might be a good data structure for specific workloads like graph algorithms.\"), mdx(\"p\", null, \"--\"), mdx(\"p\", null, \"The generalization of iterators for distributed systems are pull-based systems.\\nJust like iterators, the consumer must synchronize with the producer in order to receive data, in our case it was the \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"next()\"), \" function call but it can also be an RPC call, it is said that the consumer is polling for data.  \"), mdx(\"p\", null, \"But at a network boundary, the latency to resolve a function is in the order of milliseconds which is lifetimes in CPU time, it would be a waste to stay idle in the meantime.\", mdx(\"br\", {\n    parentName: \"p\"\n  }), \"\\n\", \"This problem is what made asynchronous programming so prevalent in modern programming.\"), mdx(\"p\", null, \"Async functions can be written like regular functions, but it must use await for each blocking call.\", mdx(\"br\", {\n    parentName: \"p\"\n  }), \"\\n\", \"By doing so, the executor could yield back and use CPU time to advance a ready task!\", mdx(\"br\", {\n    parentName: \"p\"\n  }), \"\\n\", \"To know when previously awaited tasks are ready, the executor must continuously poll the operating system for ready tasks through the \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"poll\"), \" system call.\\nInternally, each async function maintains a lazy structure that represents the perfect state machine to store just enough information to continue the execution later.\\nThis is a form of lightweight, cooperative multitasking. The alternative would be full-bown threads.    \"), mdx(\"p\", null, \"Streams unify both concepts, it is a trait for objects that can produce a sequence of elements asynchronously.\\nOne apparent problem is that the consumer has to continuously poll to receive elements. For synchronous iterators this latency problem of polling was eliminated by inlining the \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"next()\"), \" function call. For asynchronous iterators that cost can't be optimized away!  \"), mdx(\"p\", null, \"This leads us to the dual, push systems! Here the producer and consumer(s) no longer synchronize, the producer keeps creating elements and sends them to the consumer without the round-trip cost of pull systems.\\nIt is easy to see that a producer outpacing a consumer could be problematic as the consumer might drop elements at best or crash at worst. This explains why Kafka (pull) has a higher latency than RabbitMQ (push), however, RabbitMQ latencies degrade significantly at throughputs higher than 30 MB/s.\"));\n}\n;\nMDXContent.isMDXComponent = true;","excerpt":"Lazy evaluation is a concept that appears in multiple branches of computer science.\nIt is the idea to pre-emptively do less work and defer…","timeToRead":4,"banner":null}},"pageContext":{"slug":"/the-costs-of-laziness","formatString":"DD.MM.YYYY"}},"staticQueryHashes":["2744905544","3090400250","318001574"]}