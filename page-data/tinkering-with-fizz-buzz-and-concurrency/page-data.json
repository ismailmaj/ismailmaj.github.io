{"componentChunkName":"component---node-modules-lekoarts-gatsby-theme-minimal-blog-core-src-templates-post-query-tsx","path":"/tinkering-with-fizz-buzz-and-concurrency","result":{"data":{"post":{"slug":"/tinkering-with-fizz-buzz-and-concurrency","title":"tinkering with fizz buzz and concurrency","date":"20.12.2022","tags":[{"name":"Rust, Performance, Concurrency","slug":"rust-performance-concurrency"}],"description":"tinkering with fizz buzz and concurrency","canonicalUrl":null,"body":"var _excluded = [\"components\"];\nfunction _extends() { _extends = Object.assign ? Object.assign.bind() : function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n/* @jsxRuntime classic */\n/* @jsx mdx */\n\nvar _frontmatter = {\n  \"title\": \"tinkering with fizz buzz and concurrency\",\n  \"date\": \"2022-12-20T00:00:00.000Z\",\n  \"description\": \"tinkering with fizz buzz and concurrency\",\n  \"tags\": [\"Rust, Performance, Concurrency\"]\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n    props = _objectWithoutProperties(_ref, _excluded);\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h1\", null), mdx(\"p\", null, \"Let's get a baseline of the performance we could expect with a naive implementation of fizzbuzz in Python.  \"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, \"i = 1\\nwhile True:\\n    if i % 15 == 0:\\n        print(\\\"FizzBuzz\\\")\\n    elif i % 3 == 0:\\n        print(\\\"Fizz\\\")\\n    elif i % 5 == 0:\\n        print(\\\"Buzz\\\")\\n    else:\\n        print(i)\\n    i += 1\\n\")), mdx(\"p\", null, \"using \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"pv(1)\"), \" and redirecting to \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"/dev/null\"), \" we reach a whopping 30 MiB/s.  \"), mdx(\"p\", null, \"For the upper bound, we'll use the GNU utility \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"yes\"), \" known for its high throughput, it just prints lines of \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"y\"), \" repeatedly.    \"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\"\n  }, \">> yes | pv --average-rate >/dev/null\\n[10.6GiB/s]\\n\")), mdx(\"p\", null, \"Nice, let's try to reproduce this command using Rust.  \"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-rust\"\n  }, \"use std::io::{self, stdout, Write};\\n\\nfn main() -> Result<(), io::Error> {\\n    let mut writer = stdout().lock();\\n    loop {\\n        writer.write(b\\\"y\\\\n\\\")?;\\n    }\\n}\\n\")), mdx(\"p\", null, \"And we reach a throughput of ... 10 MiB/s, 3 orders of magnitude slower.      \"), mdx(\"blockquote\", null, mdx(\"p\", {\n    parentName: \"blockquote\"\n  }, \"How come Rust is slower than Python? Did I just waste my time learni-  \")), mdx(\"p\", null, \"No calm down, when running this code through \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"strace(1)\"), \" we find out that we invoke the syscall \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"write(2)\"), \" for each iteration of the loop. Reaching for the kernel is a considerable overhead and is our bottleneck so far.    \"), mdx(\"p\", null, \"The solution to this problem is buffering and it is what Python does by default.\", mdx(\"br\", {\n    parentName: \"p\"\n  }), \"\\n\", \"We can achieve the same in Rust by changing the writer from \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"Stdout\"), \" to a wrapper \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"BufWriter\"), \".\", mdx(\"br\", {\n    parentName: \"p\"\n  }), \"\\n\", \"It writes to a \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"Vec<u8>\"), \" in memory first and flushes to the underlying buffer when necessary.    \"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-diff\"\n  }, \"- let mut writer = stdout().lock();\\n+ let mut writer = BufWriter::new(stdout().lock());\\n\")), mdx(\"p\", null, \"1.67GiB/s, great but still far from the 10GiB/s of the GNU utility.  \"), mdx(\"p\", null, \"The bottleneck now is the payload. For each function call we write 2 bytes of data which -- uhh isn't great.\", mdx(\"br\", {\n    parentName: \"p\"\n  }), \"\\n\", \"The CPU atomic operation on memory is a cache line, which is typically 64 bytes on x86/x64 CPUs.\", mdx(\"br\", {\n    parentName: \"p\"\n  }), \"\\n\", \"Let's write it 32 times then.  \"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-rust\"\n  }, \"use std::io::{self, stdout, BufWriter};\\nuse std::io::prelude::*;\\n\\nconst PAGE_SIZE: usize = 4096;\\n\\nfn main() -> Result<(), io::Error> {\\n    let mut writer = BufWriter::with_capacity(PAGE_SIZE * 4, stdout().lock());\\n    loop {\\n        writer.write_all(b\\\"y\\\\ny\\\\ny\\\\ny\\\\ny\\\\ny\\\\ny\\\\ny\\\\ny\\\\ny\\\\ny\\\\ny\\\\ny\\\\ny\\\\ny\\\\ny\\\\ny\\\\ny\\\\ny\\\\ny\\\\ny\\\\ny\\\\ny\\\\ny\\\\ny\\\\ny\\\\ny\\\\ny\\\\ny\\\\ny\\\\ny\\\\ny\\\\n\\\")?;\\n    }\\n}\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\"\n  }, \">> cargo run --release | pv --average-rate >/dev/null\\n[12.2GiB/s]\\n\")), mdx(\"p\", null, \"Nice! This is better than what I expected.\"), mdx(\"p\", null, \"Let's test our theory and write 66 bytes instead of 64.   \"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\"\n  }, \">> cargo run --release | pv --average-rate >/dev/null\\n[9.6GiB/s]\\n\")), mdx(\"p\", null, \"A 27% difference, we get around the same performance penalty by choosing a buffer size that isn't a multiple of a page size.     \"), mdx(\"p\", null, \"Let's try to transfer what we learned so far to write a performant fizz buzz implementation.\", mdx(\"br\", {\n    parentName: \"p\"\n  }), \"\\n\", \"As a first optimization, we can notice that the problem is cyclic and can be made branchless.  \"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-rust\"\n  }, \"use std::io::prelude::*;\\nuse std::io::{self, stdout, BufWriter};\\nconst PAGE_SIZE: usize = 4096;\\n\\nfn main() -> Result<(), io::Error> {\\n    let mut writer = BufWriter::with_capacity(PAGE_SIZE * 4, stdout().lock());\\n    for i in (0..).step_by(15) {\\n        write!(\\n            writer,\\n            \\\"{}\\\\n{}\\\\nFizz\\\\n{}\\\\nBuzz\\\\n{}\\\\n{}\\\\n{}\\\\nFizz\\\\nBuzz\\\\n{}\\\\nFizz\\\\n{}\\\\n{}\\\\nFizzBuzz\\\\n\\\",\\n            i + 1,\\n            i + 2,\\n            i + 4,\\n            i + 6,\\n            i + 7,\\n            i + 8,\\n            i + 11,\\n            i + 13,\\n            i + 14,\\n        )?;\\n    }\\n    Ok(())\\n}\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\"\n  }, \">> cargo run --release | pv --average-rate >/dev/null\\n[ 825MiB/s]\\n\")), mdx(\"p\", null, \"We are an order of magnitude off.  \"), mdx(\"p\", null, \"When running the following code on a perf flame graph, we can notice that 66% of the time is spent on integer to string conversion which is commonly named \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"itoa\"), \".\", mdx(\"br\", {\n    parentName: \"p\"\n  }), \"\\n\", \"We are clearly CPU bound now. This can be solved by either multi-core parallelism or low-level optimization of the \\\"hot\\\" loop. We'll start by the latter.   \"), mdx(\"p\", null, \"We'll use the \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"itoap\"), \" crate as it's one of the fastest simd itoa implementation based on \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"sse2\"), \".\", mdx(\"br\", {\n    parentName: \"p\"\n  }), \"\\n\", \"It also writes numbers from the most significant digit first making the whole operation sequential.  \"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-rust\"\n  }, \"use std::io::prelude::*;\\nuse std::io::{self, stdout};\\n\\nuse itoap::write_to_vec;\\n\\nconst PAGE_SIZE: usize = 4096;\\nconst CHUNK_SIZE: usize = 15; // write 15 elements at a time\\nconst CHUNK_MAX_BYTES: usize = 359; // 39 * 8 u64 + 47 bytes of text\\n\\nconst BUFFER_SIZE: usize = PAGE_SIZE * 32; // 128 KiB fits in the L2 cache of most processors\\n\\nconst BATCH_PER_PAGE: usize = PAGE_SIZE / CHUNK_MAX_BYTES;\\nconst BATCH_SIZE: usize = BATCH_PER_PAGE * 32;\\n\\nfn main() -> Result<(), io::Error> {\\n    let mut writer = stdout().lock();\\n    let mut i = 0;\\n    loop {\\n        let mut buf = Vec::<u8>::with_capacity(BUFFER_SIZE);\\n        (0..BATCH_SIZE).for_each(|_| {\\n            write_chunk(&mut buf, i);\\n            i += CHUNK_SIZE;\\n        });\\n        writer.write_all(&buf)?;\\n    }\\n}\\n\\n#[inline(always)]\\nfn write_chunk(buf: &mut Vec<u8>, i: usize) {\\n    write_to_vec(buf, i + 1);\\n    buf.push(b'\\\\n');\\n    write_to_vec(buf, i + 2);\\n    buf.extend(b\\\"\\\\nFizz\\\\n\\\");\\n    write_to_vec(buf, i + 4);\\n    buf.extend(b\\\"\\\\nBuzz\\\\nFizz\\\\n\\\");\\n    write_to_vec(buf, i + 7);\\n    buf.push(b'\\\\n');\\n    write_to_vec(buf, i + 8);\\n    buf.extend(b\\\"\\\\nFizz\\\\nBuzz\\\\n\\\");\\n    write_to_vec(buf, i + 11);\\n    buf.extend(b\\\"\\\\nFizz\\\\n\\\");\\n    write_to_vec(buf, i + 13);\\n    buf.push(b'\\\\n');\\n    write_to_vec(buf, i + 14);\\n    buf.extend(b\\\"\\\\nFizzBuzz\\\\n\\\");\\n}\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\"\n  }, \">> cargo run --release | pv --average-rate >/dev/null\\n[3.56GiB/s]\\n\")), mdx(\"p\", null, \"Not too bad for safe Rust that is still readable.\", mdx(\"br\", {\n    parentName: \"p\"\n  }), \"\\n\", \"Amusingly, reusing buffers didn't have any impact on the throughput.\", mdx(\"br\", {\n    parentName: \"p\"\n  }), \"\\n\", \"I'm guessing the allocator is smart enough to reuse buffers with the same capacity.  \"), mdx(\"p\", null, \"Now that we got reasonable single threaded performance we could use all the cores of our processor.  \"), mdx(\"p\", null, \"Since we know that we compute \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"CHUNK_SIZE\"), \" * \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"BATCH_SIZE\"), \" = x elements per loop, we could make each thread compute x elements at an offset i.e.\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"thread 1: from 0 to x   \"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"thread 2: from x to 2x\", mdx(\"br\", {\n    parentName: \"li\"\n  }), \"... \")), mdx(\"p\", null, \"We'll end up with as many buffers as threads.\", mdx(\"br\", {\n    parentName: \"p\"\n  }), \"\\n\", \"It's possible to write all the buffers in a single syscall thanks to vectored I/O!\"), mdx(\"p\", null, \"The last thing we need to deal with is inter-thread communication. We'll use bounded channels to communicate buffers from worker threads to the main thread.   \"), mdx(\"p\", null, \"The following program reaches a throughput of 6GiB/s on my 5950x AMD CPU.  \"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-rust\"\n  }, \"#![feature(write_all_vectored)]\\nuse std::io;\\nuse std::io::prelude::*;\\nuse std::sync::mpsc::sync_channel;\\nuse std::thread::{self, available_parallelism};\\n\\nuse itoap::write_to_vec;\\n\\nconst PAGE_SIZE: usize = 4096;\\nconst CHUNK_SIZE: usize = 15;\\nconst CHUNK_MAX_BYTES: usize = 359;\\n\\n// limit the progression of a single worker\\nconst CHANNEL_CAPACITY: usize = 3;\\n\\nconst BUFFER_SIZE: usize = PAGE_SIZE * 128; // < L2 cache on 5950x\\nconst BATCH_PER_PAGE: usize = PAGE_SIZE / CHUNK_MAX_BYTES;\\nconst BATCH_SIZE: usize = BATCH_PER_PAGE * 128;\\n\\nfn main() -> Result<(), io::Error> {\\n    let workers_count = available_parallelism()?.get() - 1;\\n\\n    let receivers = (0..workers_count)\\n        .map(|thread_id| {\\n            let (sender, receiver) = sync_channel(CHANNEL_CAPACITY);\\n            thread::spawn(move || {\\n                // offset for this thread\\n                let mut i = thread_id * (CHUNK_SIZE * BATCH_SIZE);\\n                loop {\\n                    let mut buf = Vec::<u8>::with_capacity(BUFFER_SIZE);\\n                    (0..BATCH_SIZE).for_each(|_| {\\n                        write_chunk(&mut buf, i);\\n                        i += CHUNK_SIZE;\\n                    });\\n\\n                    sender\\n                        .send(buf)\\n                        .unwrap_or_else(|_| \\n                            panic!(\\\"thread {} couldn't send\\\", thread_id)\\n                        );\\n\\n                    // skip work done by other workers\\n                    i += (workers_count - 1) * (CHUNK_SIZE * BATCH_SIZE);\\n                }\\n            });\\n            receiver\\n        })\\n        .collect::<Vec<_>>();\\n\\n    let mut writer = io::stdout().lock();\\n    loop {\\n        let mut buffers = receivers\\n            .iter()\\n            .enumerate()\\n            .map(|(i, r)| {\\n                r.recv()\\n                    .unwrap_or_else(|_| panic!(\\\"worker thread {} died\\\", i))\\n            })\\n            .collect::<Vec<_>>();\\n\\n        writer.write_all_vectored(\\n            &mut buffers\\n                .iter_mut()\\n                .map(|b| io::IoSlice::new(b))\\n                .collect::<Vec<_>>(),\\n        )?;\\n    }\\n}\\n\\n#[inline(always)]\\nfn write_chunk(buf: &mut Vec<u8>, i: usize) {\\n    write_to_vec(buf, i + 1);\\n    buf.push(b'\\\\n');\\n    write_to_vec(buf, i + 2);\\n    buf.extend(b\\\"\\\\nFizz\\\\n\\\");\\n    write_to_vec(buf, i + 4);\\n    buf.extend(b\\\"\\\\nBuzz\\\\nFizz\\\\n\\\");\\n    write_to_vec(buf, i + 7);\\n    buf.push(b'\\\\n');\\n    write_to_vec(buf, i + 8);\\n    buf.extend(b\\\"\\\\nFizz\\\\nBuzz\\\\n\\\");\\n    write_to_vec(buf, i + 11);\\n    buf.extend(b\\\"\\\\nFizz\\\\n\\\");\\n    write_to_vec(buf, i + 13);\\n    buf.push(b'\\\\n');\\n    write_to_vec(buf, i + 14);\\n    buf.extend(b\\\"\\\\nFizzBuzz\\\\n\\\");\\n}\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\"\n  }, \">> cargo run --release | pv --average-rate >/dev/null\\n[6.07GiB/s]\\n\")), mdx(\"p\", null, \"It\\u2019s possible to go even further, but that either requires using obscure system calls or a more complex algorithm that uses the ever increasing property of fizz buzz. \"));\n}\n;\nMDXContent.isMDXComponent = true;","excerpt":"Let's get a baseline of the performance we could expect with a naive implementation of fizzbuzz in Python.   using  pv(1)  and redirectingâ€¦","timeToRead":2,"banner":null}},"pageContext":{"slug":"/tinkering-with-fizz-buzz-and-concurrency","formatString":"DD.MM.YYYY"}},"staticQueryHashes":["2744905544","3090400250","318001574"]}